{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bb012007-ab33-41c9-96fe-0d8d29fce69d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "##Validando a SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9f47e85e-40ed-4af3-8f0a-62d799379710",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - hive</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"/?o=690697175050107#setting/sparkui/0607-014224-e1yhbh5y/driver-5642451572268299525\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.3.2</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[8]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Databricks Shell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "\n            <div>\n                <p><b>SparkSession - hive</b></p>\n                \n        <div>\n            <p><b>SparkContext</b></p>\n\n            <p><a href=\"/?o=690697175050107#setting/sparkui/0607-014224-e1yhbh5y/driver-5642451572268299525\">Spark UI</a></p>\n\n            <dl>\n              <dt>Version</dt>\n                <dd><code>v3.3.2</code></dd>\n              <dt>Master</dt>\n                <dd><code>local[8]</code></dd>\n              <dt>AppName</dt>\n                <dd><code>Databricks Shell</code></dd>\n            </dl>\n        </div>\n        \n            </div>\n        ",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "textData": null,
       "type": "htmlSandbox"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2b235b0d-5e6d-41fd-b9ed-fc9a2367efa6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "##Conectando Azure ADLS Gen2 no Databricks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "61839b6f-63e3-4a67-ab56-3e2678ebe19c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "###Mostrando os pontos de montagem no cluster Databricks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "996be72e-0fb9-4953-bc2c-7b1b605cdf8e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>mountPoint</th><th>source</th><th>encryptionType</th></tr></thead><tbody><tr><td>/mnt/datalake6d3129a9a4390b0a/gold</td><td>wasbs://gold@datalake6d3129a9a4390b0a.blob.core.windows.net</td><td></td></tr><tr><td>/mnt/datalakeedda2e0be8d3ec5f/bronze</td><td>wasbs://bronze@datalakeedda2e0be8d3ec5f.blob.core.windows.net</td><td></td></tr><tr><td>/mnt/datalake246d728b13561613/lading-zone</td><td>wasbs://lading-zone@datalake246d728b13561613.blob.core.windows.net</td><td></td></tr><tr><td>/mnt/datalake4b6c87c48101c278/bronze</td><td>wasbs://bronze@datalake4b6c87c48101c278.blob.core.windows.net</td><td></td></tr><tr><td>/mnt/datalake4b6c87c48101c278/gold</td><td>wasbs://gold@datalake4b6c87c48101c278.blob.core.windows.net</td><td></td></tr><tr><td>/databricks-datasets</td><td>databricks-datasets</td><td></td></tr><tr><td>/mnt/datalake246d728b13561613/bronze</td><td>wasbs://bronze@datalake246d728b13561613.blob.core.windows.net</td><td></td></tr><tr><td>/mnt/datalakee66472c14f9678fd/landing-zone</td><td>wasbs://landing-zone@datalakee66472c14f9678fd.blob.core.windows.net</td><td></td></tr><tr><td>/databricks/mlflow-tracking</td><td>databricks/mlflow-tracking</td><td>sse-s3</td></tr><tr><td>/mnt/datalake4b6c87c48101c278/silver</td><td>wasbs://silver@datalake4b6c87c48101c278.blob.core.windows.net</td><td></td></tr><tr><td>/mnt/datalakeedda2e0be8d3ec5f/landing-zone</td><td>wasbs://landing-zone@datalakeedda2e0be8d3ec5f.blob.core.windows.net</td><td></td></tr><tr><td>/databricks-results</td><td>databricks-results</td><td>sse-s3</td></tr><tr><td>/mnt/datalake246d728b13561613/silver</td><td>wasbs://silver@datalake246d728b13561613.blob.core.windows.net</td><td></td></tr><tr><td>/mnt/datalakee66472c14f9678fd/gold</td><td>wasbs://gold@datalakee66472c14f9678fd.blob.core.windows.net</td><td></td></tr><tr><td>/mnt/datalakee66472c14f9678fd/silver</td><td>wasbs://silver@datalakee66472c14f9678fd.blob.core.windows.net</td><td></td></tr><tr><td>/databricks/mlflow-registry</td><td>databricks/mlflow-registry</td><td>sse-s3</td></tr><tr><td>/mnt/datalake6d3129a9a4390b0a/silver</td><td>wasbs://silver@datalake6d3129a9a4390b0a.blob.core.windows.net</td><td></td></tr><tr><td>/mnt/datalake246d728b13561613/gold</td><td>wasbs://gold@datalake246d728b13561613.blob.core.windows.net</td><td></td></tr><tr><td>/mnt/datalake246d728b13561613/landing-zone</td><td>wasbs://landing-zone@datalake246d728b13561613.blob.core.windows.net</td><td></td></tr><tr><td>/mnt/datalakeedda2e0be8d3ec5f/gold</td><td>wasbs://gold@datalakeedda2e0be8d3ec5f.blob.core.windows.net</td><td></td></tr><tr><td>/mnt/datalakeedda2e0be8d3ec5f/lading-zone</td><td>wasbs://lading-zone@datalakeedda2e0be8d3ec5f.blob.core.windows.net</td><td></td></tr><tr><td>/mnt/datalakee66472c14f9678fd/lading-zone</td><td>wasbs://lading-zone@datalakee66472c14f9678fd.blob.core.windows.net</td><td></td></tr><tr><td>/mnt/datalake6d3129a9a4390b0a/bronze</td><td>wasbs://bronze@datalake6d3129a9a4390b0a.blob.core.windows.net</td><td></td></tr><tr><td>/mnt/datalakeedda2e0be8d3ec5f/silver</td><td>wasbs://silver@datalakeedda2e0be8d3ec5f.blob.core.windows.net</td><td></td></tr><tr><td>/mnt/datalake6d3129a9a4390b0a/landing-zone</td><td>wasbs://landing-zone@datalake6d3129a9a4390b0a.blob.core.windows.net</td><td></td></tr><tr><td>/mnt/datalake4b6c87c48101c278/landing-zone</td><td>wasbs://landing-zone@datalake4b6c87c48101c278.blob.core.windows.net</td><td></td></tr><tr><td>/</td><td>DatabricksRoot</td><td>sse-s3</td></tr><tr><td>/mnt/datalake6d3129a9a4390b0a/lading-zone</td><td>wasbs://lading-zone@datalake6d3129a9a4390b0a.blob.core.windows.net</td><td></td></tr><tr><td>/mnt/datalakee66472c14f9678fd/bronze</td><td>wasbs://bronze@datalakee66472c14f9678fd.blob.core.windows.net</td><td></td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "/mnt/datalake6d3129a9a4390b0a/gold",
         "wasbs://gold@datalake6d3129a9a4390b0a.blob.core.windows.net",
         ""
        ],
        [
         "/mnt/datalakeedda2e0be8d3ec5f/bronze",
         "wasbs://bronze@datalakeedda2e0be8d3ec5f.blob.core.windows.net",
         ""
        ],
        [
         "/mnt/datalake246d728b13561613/lading-zone",
         "wasbs://lading-zone@datalake246d728b13561613.blob.core.windows.net",
         ""
        ],
        [
         "/mnt/datalake4b6c87c48101c278/bronze",
         "wasbs://bronze@datalake4b6c87c48101c278.blob.core.windows.net",
         ""
        ],
        [
         "/mnt/datalake4b6c87c48101c278/gold",
         "wasbs://gold@datalake4b6c87c48101c278.blob.core.windows.net",
         ""
        ],
        [
         "/databricks-datasets",
         "databricks-datasets",
         ""
        ],
        [
         "/mnt/datalake246d728b13561613/bronze",
         "wasbs://bronze@datalake246d728b13561613.blob.core.windows.net",
         ""
        ],
        [
         "/mnt/datalakee66472c14f9678fd/landing-zone",
         "wasbs://landing-zone@datalakee66472c14f9678fd.blob.core.windows.net",
         ""
        ],
        [
         "/databricks/mlflow-tracking",
         "databricks/mlflow-tracking",
         "sse-s3"
        ],
        [
         "/mnt/datalake4b6c87c48101c278/silver",
         "wasbs://silver@datalake4b6c87c48101c278.blob.core.windows.net",
         ""
        ],
        [
         "/mnt/datalakeedda2e0be8d3ec5f/landing-zone",
         "wasbs://landing-zone@datalakeedda2e0be8d3ec5f.blob.core.windows.net",
         ""
        ],
        [
         "/databricks-results",
         "databricks-results",
         "sse-s3"
        ],
        [
         "/mnt/datalake246d728b13561613/silver",
         "wasbs://silver@datalake246d728b13561613.blob.core.windows.net",
         ""
        ],
        [
         "/mnt/datalakee66472c14f9678fd/gold",
         "wasbs://gold@datalakee66472c14f9678fd.blob.core.windows.net",
         ""
        ],
        [
         "/mnt/datalakee66472c14f9678fd/silver",
         "wasbs://silver@datalakee66472c14f9678fd.blob.core.windows.net",
         ""
        ],
        [
         "/databricks/mlflow-registry",
         "databricks/mlflow-registry",
         "sse-s3"
        ],
        [
         "/mnt/datalake6d3129a9a4390b0a/silver",
         "wasbs://silver@datalake6d3129a9a4390b0a.blob.core.windows.net",
         ""
        ],
        [
         "/mnt/datalake246d728b13561613/gold",
         "wasbs://gold@datalake246d728b13561613.blob.core.windows.net",
         ""
        ],
        [
         "/mnt/datalake246d728b13561613/landing-zone",
         "wasbs://landing-zone@datalake246d728b13561613.blob.core.windows.net",
         ""
        ],
        [
         "/mnt/datalakeedda2e0be8d3ec5f/gold",
         "wasbs://gold@datalakeedda2e0be8d3ec5f.blob.core.windows.net",
         ""
        ],
        [
         "/mnt/datalakeedda2e0be8d3ec5f/lading-zone",
         "wasbs://lading-zone@datalakeedda2e0be8d3ec5f.blob.core.windows.net",
         ""
        ],
        [
         "/mnt/datalakee66472c14f9678fd/lading-zone",
         "wasbs://lading-zone@datalakee66472c14f9678fd.blob.core.windows.net",
         ""
        ],
        [
         "/mnt/datalake6d3129a9a4390b0a/bronze",
         "wasbs://bronze@datalake6d3129a9a4390b0a.blob.core.windows.net",
         ""
        ],
        [
         "/mnt/datalakeedda2e0be8d3ec5f/silver",
         "wasbs://silver@datalakeedda2e0be8d3ec5f.blob.core.windows.net",
         ""
        ],
        [
         "/mnt/datalake6d3129a9a4390b0a/landing-zone",
         "wasbs://landing-zone@datalake6d3129a9a4390b0a.blob.core.windows.net",
         ""
        ],
        [
         "/mnt/datalake4b6c87c48101c278/landing-zone",
         "wasbs://landing-zone@datalake4b6c87c48101c278.blob.core.windows.net",
         ""
        ],
        [
         "/",
         "DatabricksRoot",
         "sse-s3"
        ],
        [
         "/mnt/datalake6d3129a9a4390b0a/lading-zone",
         "wasbs://lading-zone@datalake6d3129a9a4390b0a.blob.core.windows.net",
         ""
        ],
        [
         "/mnt/datalakee66472c14f9678fd/bronze",
         "wasbs://bronze@datalakee66472c14f9678fd.blob.core.windows.net",
         ""
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "mountPoint",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "source",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "encryptionType",
         "type": "\"string\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(dbutils.fs.mounts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c5da882a-1966-4a71-bb6f-58863fa2e301",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "###Desmontando os pontos de montagem não utilizados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c2bea950-5918-46f5-a6a1-b0bcb0dfd338",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#dbutils.fs.unmount('/mnt/datalake6f2d8d16eba38233/bronze')\n",
    "#dbutils.fs.unmount('/mnt/datalakefc6082cb60bef06c/bronze')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1e233d75-fd2d-442a-a085-bb59f3edf995",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Definindo uma função para montar um ADLS com um ponto de montagem com ADLS SAS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "058a3cc4-370c-4abf-8c60-39a7f3f302d1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "storageAccountName = \"datalake4b6c87c48101c278\"\n",
    "storageAccountAccessKey = \"\"\n",
    "sasToken = \"sv=2024-11-04&ss=bfqt&srt=sco&sp=rwdlacupyx&se=2025-06-07T12:17:21Z&st=2025-06-07T04:17:21Z&spr=https&sig=BfwzYwM%2B5YR%2FBkSSyRv0Nn%2F3riHK9Wx4P%2FQoguM%2BA%2FM%3D\"\n",
    "\n",
    "def mount_adls(blobContainerName):\n",
    "    try:\n",
    "      dbutils.fs.mount(\n",
    "        source = \"wasbs://{}@{}.blob.core.windows.net\".format(blobContainerName, storageAccountName),\n",
    "        mount_point = f\"/mnt/{storageAccountName}/{blobContainerName}\",\n",
    "        #extra_configs = {'fs.azure.account.key.' + storageAccountName + '.blob.core.windows.net': storageAccountAccessKey}\n",
    "        extra_configs = {'fs.azure.sas.' + blobContainerName + '.' + storageAccountName + '.blob.core.windows.net': sasToken}\n",
    "      )\n",
    "      print(\"OK!\")\n",
    "    except Exception as e:\n",
    "      print(\"Falha\", e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "40a6dfa7-fb55-46c5-a3a8-44e9bee8f390",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "###Montando todos os containers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8d62fdfc-2dc8-4465-98fd-834ac8ae9404",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK!\n",
      "Falha An error occurred while calling o1919.mount.\n",
      ": java.rmi.RemoteException: java.lang.IllegalArgumentException: requirement failed: Directory already mounted: /mnt/datalake4b6c87c48101c278/bronze; nested exception is: \n",
      "\tjava.lang.IllegalArgumentException: requirement failed: Directory already mounted: /mnt/datalake4b6c87c48101c278/bronze\n",
      "\tat com.databricks.backend.daemon.data.client.DbfsClient.send0(DbfsClient.scala:135)\n",
      "\tat com.databricks.backend.daemon.data.client.DbfsClient.sendIdempotent(DbfsClient.scala:69)\n",
      "\tat com.databricks.backend.daemon.dbutils.DBUtilsCore.createOrUpdateMount(DBUtilsCore.scala:1053)\n",
      "\tat com.databricks.backend.daemon.dbutils.DBUtilsCore.$anonfun$mount$1(DBUtilsCore.scala:1079)\n",
      "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperation$1(UsageLogging.scala:560)\n",
      "\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:657)\n",
      "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:678)\n",
      "\tat com.databricks.logging.UsageLogging.$anonfun$withAttributionContext$1(UsageLogging.scala:414)\n",
      "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n",
      "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:158)\n",
      "\tat com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:412)\n",
      "\tat com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:409)\n",
      "\tat com.databricks.backend.daemon.dbutils.FSUtils.withAttributionContext(DBUtilsCore.scala:71)\n",
      "\tat com.databricks.logging.UsageLogging.withAttributionTags(UsageLogging.scala:457)\n",
      "\tat com.databricks.logging.UsageLogging.withAttributionTags$(UsageLogging.scala:442)\n",
      "\tat com.databricks.backend.daemon.dbutils.FSUtils.withAttributionTags(DBUtilsCore.scala:71)\n",
      "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:652)\n",
      "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:569)\n",
      "\tat com.databricks.backend.daemon.dbutils.FSUtils.recordOperationWithResultTags(DBUtilsCore.scala:71)\n",
      "\tat com.databricks.logging.UsageLogging.recordOperation(UsageLogging.scala:560)\n",
      "\tat com.databricks.logging.UsageLogging.recordOperation$(UsageLogging.scala:528)\n",
      "\tat com.databricks.backend.daemon.dbutils.FSUtils.recordOperation(DBUtilsCore.scala:71)\n",
      "\tat com.databricks.backend.daemon.dbutils.FSUtils.recordDbutilsFsOp(DBUtilsCore.scala:135)\n",
      "\tat com.databricks.backend.daemon.dbutils.DBUtilsCore.mount(DBUtilsCore.scala:1073)\n",
      "\tat sun.reflect.GeneratedMethodAccessor1115.invoke(Unknown Source)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:380)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:306)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:195)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:115)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: java.lang.IllegalArgumentException: requirement failed: Directory already mounted: /mnt/datalake4b6c87c48101c278/bronze\n",
      "\tat scala.Predef$.require(Predef.scala:281)\n",
      "\tat com.databricks.backend.daemon.data.server.DefaultMetadataManager.$anonfun$insertMount$1(MetadataManager.scala:860)\n",
      "\tat com.databricks.backend.daemon.data.server.DefaultMetadataManager.$anonfun$modifyAndVerify$2(MetadataManager.scala:1242)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat com.databricks.backend.daemon.data.server.DefaultMetadataManager.withRetries(MetadataManager.scala:1015)\n",
      "\tat com.databricks.backend.daemon.data.server.DefaultMetadataManager.modifyAndVerify(MetadataManager.scala:1231)\n",
      "\tat com.databricks.backend.daemon.data.server.DefaultMetadataManager.insertMount(MetadataManager.scala:868)\n",
      "\tat com.databricks.backend.daemon.data.server.handler.MountHandler.receive(MountHandler.scala:131)\n",
      "\tat com.databricks.backend.daemon.data.server.handler.CEMountHandler.receive(MountHandler.scala:175)\n",
      "\tat com.databricks.backend.daemon.data.server.handler.DbfsRequestHandler.receive(DbfsRequestHandler.scala:16)\n",
      "\tat com.databricks.backend.daemon.data.server.handler.DbfsRequestHandler.receive$(DbfsRequestHandler.scala:15)\n",
      "\tat com.databricks.backend.daemon.data.server.handler.MountHandler.receive(MountHandler.scala:39)\n",
      "\tat com.databricks.backend.daemon.data.server.session.SessionContext.$anonfun$queryHandlers$1(SessionContext.scala:54)\n",
      "\tat com.databricks.backend.daemon.data.server.session.SessionContext.$anonfun$queryHandlers$1$adapted(SessionContext.scala:53)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat com.databricks.backend.daemon.data.server.session.SessionContext.queryHandlers(SessionContext.scala:53)\n",
      "\tat com.databricks.backend.daemon.data.server.DbfsServerBackend.$anonfun$handleOtherRpc$2(DbfsServerBackend.scala:599)\n",
      "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)\n",
      "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:290)\n",
      "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n",
      "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:286)\n",
      "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)\n",
      "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)\n",
      "\tat com.databricks.rpc.ServerBackend.withAttributionContext(ServerBackend.scala:22)\n",
      "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:96)\n",
      "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:77)\n",
      "\tat com.databricks.rpc.ServerBackend.withAttributionTags(ServerBackend.scala:22)\n",
      "\tat com.databricks.backend.daemon.data.server.DbfsServerBackend.com$databricks$backend$daemon$data$server$DbfsServerBackend$$handleOtherRpc(DbfsServerBackend.scala:599)\n",
      "\tat com.databricks.backend.daemon.data.server.DbfsServerBackend$$anonfun$receive$1.applyOrElse(DbfsServerBackend.scala:524)\n",
      "\tat com.databricks.backend.daemon.data.server.DbfsServerBackend$$anonfun$receive$1.applyOrElse(DbfsServerBackend.scala:431)\n",
      "\tat com.databricks.rpc.ServerBackend.$anonfun$internalReceive0$2(ServerBackend.scala:174)\n",
      "\tat com.databricks.rpc.ServerBackend$$anonfun$commonReceive$1.applyOrElse(ServerBackend.scala:200)\n",
      "\tat com.databricks.rpc.ServerBackend$$anonfun$commonReceive$1.applyOrElse(ServerBackend.scala:200)\n",
      "\tat com.databricks.rpc.ServerBackend.internalReceive0(ServerBackend.scala:171)\n",
      "\tat com.databricks.rpc.ServerBackend.$anonfun$internalReceive$1(ServerBackend.scala:147)\n",
      "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperation$1(UsageLogging.scala:510)\n",
      "\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:616)\n",
      "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:643)\n",
      "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)\n",
      "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:290)\n",
      "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n",
      "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:286)\n",
      "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)\n",
      "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)\n",
      "\tat com.databricks.rpc.ServerBackend.withAttributionContext(ServerBackend.scala:22)\n",
      "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:96)\n",
      "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:77)\n",
      "\tat com.databricks.rpc.ServerBackend.withAttributionTags(ServerBackend.scala:22)\n",
      "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:611)\n",
      "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:519)\n",
      "\tat com.databricks.rpc.ServerBackend.recordOperationWithResultTags(ServerBackend.scala:22)\n",
      "\tat com.databricks.logging.UsageLogging.recordOperation(UsageLogging.scala:511)\n",
      "\tat com.databricks.logging.UsageLogging.recordOperation$(UsageLogging.scala:475)\n",
      "\tat com.databricks.rpc.ServerBackend.recordOperation(ServerBackend.scala:22)\n",
      "\tat com.databricks.rpc.ServerBackend.internalReceive(ServerBackend.scala:146)\n",
      "\tat com.databricks.rpc.JettyServer$RequestManager.handleRPC(JettyServer.scala:1033)\n",
      "\tat com.databricks.rpc.JettyServer$RequestManager.handleRequestAndRespond(JettyServer.scala:953)\n",
      "\tat com.databricks.rpc.JettyServer$RequestManager.$anonfun$handleHttp$5(JettyServer.scala:548)\n",
      "\tat com.databricks.rpc.JettyServer$RequestManager.$anonfun$handleHttp$5$adapted(JettyServer.scala:513)\n",
      "\tat com.databricks.logging.activity.ActivityContextFactory$.$anonfun$withActivityInternal$12(ActivityContextFactory.scala:860)\n",
      "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)\n",
      "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:290)\n",
      "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n",
      "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:286)\n",
      "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)\n",
      "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)\n",
      "\tat com.databricks.logging.activity.ActivityContextFactory$.withAttributionContext(ActivityContextFactory.scala:53)\n",
      "\tat com.databricks.logging.activity.ActivityContextFactory$.$anonfun$withActivityInternal$2(ActivityContextFactory.scala:860)\n",
      "\tat com.databricks.context.integrity.IntegrityCheckContext$ThreadLocalStorage$.withValue(IntegrityCheckContext.scala:73)\n",
      "\tat com.databricks.logging.activity.ActivityContextFactory$.withActivityInternal(ActivityContextFactory.scala:823)\n",
      "\tat com.databricks.logging.activity.ActivityContextFactory$.withActivityInternal(ActivityContextFactory.scala:805)\n",
      "\tat com.databricks.logging.activity.ActivityContextFactory$.$anonfun$withServiceRequestActivity$15(ActivityContextFactory.scala:291)\n",
      "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)\n",
      "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:290)\n",
      "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n",
      "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:286)\n",
      "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)\n",
      "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)\n",
      "\tat com.databricks.logging.activity.ActivityContextFactory$.withAttributionContext(ActivityContextFactory.scala:53)\n",
      "\tat com.databricks.logging.activity.ActivityContextFactory$.withServiceRequestActivity(ActivityContextFactory.scala:291)\n",
      "\tat com.databricks.rpc.JettyServer$RequestManager.handleHttp(JettyServer.scala:513)\n",
      "\tat com.databricks.rpc.JettyServer$RequestManager.doPost(JettyServer.scala:408)\n",
      "\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:665)\n",
      "\tat com.databricks.rpc.HttpServletWithPatch.service(HttpServletWithPatch.scala:33)\n",
      "\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:750)\n",
      "\tat org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)\n",
      "\tat org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:554)\n",
      "\tat org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:190)\n",
      "\tat org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:505)\n",
      "\tat org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)\n",
      "\tat org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)\n",
      "\tat org.eclipse.jetty.server.Server.handle(Server.java:516)\n",
      "\tat org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:487)\n",
      "\tat org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:732)\n",
      "\tat org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:479)\n",
      "\tat org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)\n",
      "\tat org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)\n",
      "\tat org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)\n",
      "\tat org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)\n",
      "\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338)\n",
      "\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315)\n",
      "\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)\n",
      "\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)\n",
      "\tat org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:409)\n",
      "\tat com.databricks.rpc.InstrumentedQueuedThreadPool$$anon$1.$anonfun$run$2(InstrumentedQueuedThreadPool.scala:110)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)\n",
      "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:290)\n",
      "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n",
      "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:286)\n",
      "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)\n",
      "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)\n",
      "\tat com.databricks.rpc.InstrumentedQueuedThreadPool.withAttributionContext(InstrumentedQueuedThreadPool.scala:45)\n",
      "\tat com.databricks.rpc.InstrumentedQueuedThreadPool$$anon$1.$anonfun$run$1(InstrumentedQueuedThreadPool.scala:110)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat com.databricks.instrumentation.QueuedThreadPoolInstrumenter.trackActiveThreads(QueuedThreadPoolInstrumenter.scala:132)\n",
      "\tat com.databricks.instrumentation.QueuedThreadPoolInstrumenter.trackActiveThreads$(QueuedThreadPoolInstrumenter.scala:129)\n",
      "\tat com.databricks.rpc.InstrumentedQueuedThreadPool.trackActiveThreads(InstrumentedQueuedThreadPool.scala:45)\n",
      "\tat com.databricks.rpc.InstrumentedQueuedThreadPool$$anon$1.run(InstrumentedQueuedThreadPool.scala:92)\n",
      "\tat org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)\n",
      "\tat org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)\n",
      "\tat java.lang.Thread.run(Thread.java:840)\n",
      "\n",
      "Falha An error occurred while calling o1919.mount.\n",
      ": java.rmi.RemoteException: java.lang.IllegalArgumentException: requirement failed: Directory already mounted: /mnt/datalake4b6c87c48101c278/silver; nested exception is: \n",
      "\tjava.lang.IllegalArgumentException: requirement failed: Directory already mounted: /mnt/datalake4b6c87c48101c278/silver\n",
      "\tat com.databricks.backend.daemon.data.client.DbfsClient.send0(DbfsClient.scala:135)\n",
      "\tat com.databricks.backend.daemon.data.client.DbfsClient.sendIdempotent(DbfsClient.scala:69)\n",
      "\tat com.databricks.backend.daemon.dbutils.DBUtilsCore.createOrUpdateMount(DBUtilsCore.scala:1053)\n",
      "\tat com.databricks.backend.daemon.dbutils.DBUtilsCore.$anonfun$mount$1(DBUtilsCore.scala:1079)\n",
      "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperation$1(UsageLogging.scala:560)\n",
      "\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:657)\n",
      "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:678)\n",
      "\tat com.databricks.logging.UsageLogging.$anonfun$withAttributionContext$1(UsageLogging.scala:414)\n",
      "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n",
      "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:158)\n",
      "\tat com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:412)\n",
      "\tat com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:409)\n",
      "\tat com.databricks.backend.daemon.dbutils.FSUtils.withAttributionContext(DBUtilsCore.scala:71)\n",
      "\tat com.databricks.logging.UsageLogging.withAttributionTags(UsageLogging.scala:457)\n",
      "\tat com.databricks.logging.UsageLogging.withAttributionTags$(UsageLogging.scala:442)\n",
      "\tat com.databricks.backend.daemon.dbutils.FSUtils.withAttributionTags(DBUtilsCore.scala:71)\n",
      "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:652)\n",
      "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:569)\n",
      "\tat com.databricks.backend.daemon.dbutils.FSUtils.recordOperationWithResultTags(DBUtilsCore.scala:71)\n",
      "\tat com.databricks.logging.UsageLogging.recordOperation(UsageLogging.scala:560)\n",
      "\tat com.databricks.logging.UsageLogging.recordOperation$(UsageLogging.scala:528)\n",
      "\tat com.databricks.backend.daemon.dbutils.FSUtils.recordOperation(DBUtilsCore.scala:71)\n",
      "\tat com.databricks.backend.daemon.dbutils.FSUtils.recordDbutilsFsOp(DBUtilsCore.scala:135)\n",
      "\tat com.databricks.backend.daemon.dbutils.DBUtilsCore.mount(DBUtilsCore.scala:1073)\n",
      "\tat sun.reflect.GeneratedMethodAccessor1115.invoke(Unknown Source)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:380)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:306)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:195)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:115)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: java.lang.IllegalArgumentException: requirement failed: Directory already mounted: /mnt/datalake4b6c87c48101c278/silver\n",
      "\tat scala.Predef$.require(Predef.scala:281)\n",
      "\tat com.databricks.backend.daemon.data.server.DefaultMetadataManager.$anonfun$insertMount$1(MetadataManager.scala:860)\n",
      "\tat com.databricks.backend.daemon.data.server.DefaultMetadataManager.$anonfun$modifyAndVerify$2(MetadataManager.scala:1242)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat com.databricks.backend.daemon.data.server.DefaultMetadataManager.withRetries(MetadataManager.scala:1015)\n",
      "\tat com.databricks.backend.daemon.data.server.DefaultMetadataManager.modifyAndVerify(MetadataManager.scala:1231)\n",
      "\tat com.databricks.backend.daemon.data.server.DefaultMetadataManager.insertMount(MetadataManager.scala:868)\n",
      "\tat com.databricks.backend.daemon.data.server.handler.MountHandler.receive(MountHandler.scala:131)\n",
      "\tat com.databricks.backend.daemon.data.server.handler.CEMountHandler.receive(MountHandler.scala:175)\n",
      "\tat com.databricks.backend.daemon.data.server.handler.DbfsRequestHandler.receive(DbfsRequestHandler.scala:16)\n",
      "\tat com.databricks.backend.daemon.data.server.handler.DbfsRequestHandler.receive$(DbfsRequestHandler.scala:15)\n",
      "\tat com.databricks.backend.daemon.data.server.handler.MountHandler.receive(MountHandler.scala:39)\n",
      "\tat com.databricks.backend.daemon.data.server.session.SessionContext.$anonfun$queryHandlers$1(SessionContext.scala:54)\n",
      "\tat com.databricks.backend.daemon.data.server.session.SessionContext.$anonfun$queryHandlers$1$adapted(SessionContext.scala:53)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat com.databricks.backend.daemon.data.server.session.SessionContext.queryHandlers(SessionContext.scala:53)\n",
      "\tat com.databricks.backend.daemon.data.server.DbfsServerBackend.$anonfun$handleOtherRpc$2(DbfsServerBackend.scala:599)\n",
      "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)\n",
      "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:290)\n",
      "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n",
      "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:286)\n",
      "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)\n",
      "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)\n",
      "\tat com.databricks.rpc.ServerBackend.withAttributionContext(ServerBackend.scala:22)\n",
      "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:96)\n",
      "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:77)\n",
      "\tat com.databricks.rpc.ServerBackend.withAttributionTags(ServerBackend.scala:22)\n",
      "\tat com.databricks.backend.daemon.data.server.DbfsServerBackend.com$databricks$backend$daemon$data$server$DbfsServerBackend$$handleOtherRpc(DbfsServerBackend.scala:599)\n",
      "\tat com.databricks.backend.daemon.data.server.DbfsServerBackend$$anonfun$receive$1.applyOrElse(DbfsServerBackend.scala:524)\n",
      "\tat com.databricks.backend.daemon.data.server.DbfsServerBackend$$anonfun$receive$1.applyOrElse(DbfsServerBackend.scala:431)\n",
      "\tat com.databricks.rpc.ServerBackend.$anonfun$internalReceive0$2(ServerBackend.scala:174)\n",
      "\tat com.databricks.rpc.ServerBackend$$anonfun$commonReceive$1.applyOrElse(ServerBackend.scala:200)\n",
      "\tat com.databricks.rpc.ServerBackend$$anonfun$commonReceive$1.applyOrElse(ServerBackend.scala:200)\n",
      "\tat com.databricks.rpc.ServerBackend.internalReceive0(ServerBackend.scala:171)\n",
      "\tat com.databricks.rpc.ServerBackend.$anonfun$internalReceive$1(ServerBackend.scala:147)\n",
      "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperation$1(UsageLogging.scala:510)\n",
      "\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:616)\n",
      "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:643)\n",
      "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)\n",
      "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:290)\n",
      "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n",
      "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:286)\n",
      "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)\n",
      "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)\n",
      "\tat com.databricks.rpc.ServerBackend.withAttributionContext(ServerBackend.scala:22)\n",
      "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:96)\n",
      "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:77)\n",
      "\tat com.databricks.rpc.ServerBackend.withAttributionTags(ServerBackend.scala:22)\n",
      "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:611)\n",
      "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:519)\n",
      "\tat com.databricks.rpc.ServerBackend.recordOperationWithResultTags(ServerBackend.scala:22)\n",
      "\tat com.databricks.logging.UsageLogging.recordOperation(UsageLogging.scala:511)\n",
      "\tat com.databricks.logging.UsageLogging.recordOperation$(UsageLogging.scala:475)\n",
      "\tat com.databricks.rpc.ServerBackend.recordOperation(ServerBackend.scala:22)\n",
      "\tat com.databricks.rpc.ServerBackend.internalReceive(ServerBackend.scala:146)\n",
      "\tat com.databricks.rpc.JettyServer$RequestManager.handleRPC(JettyServer.scala:1033)\n",
      "\tat com.databricks.rpc.JettyServer$RequestManager.handleRequestAndRespond(JettyServer.scala:953)\n",
      "\tat com.databricks.rpc.JettyServer$RequestManager.$anonfun$handleHttp$5(JettyServer.scala:548)\n",
      "\tat com.databricks.rpc.JettyServer$RequestManager.$anonfun$handleHttp$5$adapted(JettyServer.scala:513)\n",
      "\tat com.databricks.logging.activity.ActivityContextFactory$.$anonfun$withActivityInternal$12(ActivityContextFactory.scala:860)\n",
      "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)\n",
      "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:290)\n",
      "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n",
      "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:286)\n",
      "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)\n",
      "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)\n",
      "\tat com.databricks.logging.activity.ActivityContextFactory$.withAttributionContext(ActivityContextFactory.scala:53)\n",
      "\tat com.databricks.logging.activity.ActivityContextFactory$.$anonfun$withActivityInternal$2(ActivityContextFactory.scala:860)\n",
      "\tat com.databricks.context.integrity.IntegrityCheckContext$ThreadLocalStorage$.withValue(IntegrityCheckContext.scala:73)\n",
      "\tat com.databricks.logging.activity.ActivityContextFactory$.withActivityInternal(ActivityContextFactory.scala:823)\n",
      "\tat com.databricks.logging.activity.ActivityContextFactory$.withActivityInternal(ActivityContextFactory.scala:805)\n",
      "\tat com.databricks.logging.activity.ActivityContextFactory$.$anonfun$withServiceRequestActivity$15(ActivityContextFactory.scala:291)\n",
      "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)\n",
      "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:290)\n",
      "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n",
      "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:286)\n",
      "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)\n",
      "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)\n",
      "\tat com.databricks.logging.activity.ActivityContextFactory$.withAttributionContext(ActivityContextFactory.scala:53)\n",
      "\tat com.databricks.logging.activity.ActivityContextFactory$.withServiceRequestActivity(ActivityContextFactory.scala:291)\n",
      "\tat com.databricks.rpc.JettyServer$RequestManager.handleHttp(JettyServer.scala:513)\n",
      "\tat com.databricks.rpc.JettyServer$RequestManager.doPost(JettyServer.scala:408)\n",
      "\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:665)\n",
      "\tat com.databricks.rpc.HttpServletWithPatch.service(HttpServletWithPatch.scala:33)\n",
      "\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:750)\n",
      "\tat org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)\n",
      "\tat org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:554)\n",
      "\tat org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:190)\n",
      "\tat org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:505)\n",
      "\tat org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)\n",
      "\tat org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)\n",
      "\tat org.eclipse.jetty.server.Server.handle(Server.java:516)\n",
      "\tat org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:487)\n",
      "\tat org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:732)\n",
      "\tat org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:479)\n",
      "\tat org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)\n",
      "\tat org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)\n",
      "\tat org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)\n",
      "\tat org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)\n",
      "\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338)\n",
      "\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315)\n",
      "\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)\n",
      "\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)\n",
      "\tat org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:409)\n",
      "\tat com.databricks.rpc.InstrumentedQueuedThreadPool$$anon$1.$anonfun$run$2(InstrumentedQueuedThreadPool.scala:110)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)\n",
      "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:290)\n",
      "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n",
      "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:286)\n",
      "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)\n",
      "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)\n",
      "\tat com.databricks.rpc.InstrumentedQueuedThreadPool.withAttributionContext(InstrumentedQueuedThreadPool.scala:45)\n",
      "\tat com.databricks.rpc.InstrumentedQueuedThreadPool$$anon$1.$anonfun$run$1(InstrumentedQueuedThreadPool.scala:110)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat com.databricks.instrumentation.QueuedThreadPoolInstrumenter.trackActiveThreads(QueuedThreadPoolInstrumenter.scala:132)\n",
      "\tat com.databricks.instrumentation.QueuedThreadPoolInstrumenter.trackActiveThreads$(QueuedThreadPoolInstrumenter.scala:129)\n",
      "\tat com.databricks.rpc.InstrumentedQueuedThreadPool.trackActiveThreads(InstrumentedQueuedThreadPool.scala:45)\n",
      "\tat com.databricks.rpc.InstrumentedQueuedThreadPool$$anon$1.run(InstrumentedQueuedThreadPool.scala:92)\n",
      "\tat org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)\n",
      "\tat org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)\n",
      "\tat java.lang.Thread.run(Thread.java:840)\n",
      "\n",
      "Falha An error occurred while calling o1919.mount.\n",
      ": java.rmi.RemoteException: java.lang.IllegalArgumentException: requirement failed: Directory already mounted: /mnt/datalake4b6c87c48101c278/gold; nested exception is: \n",
      "\tjava.lang.IllegalArgumentException: requirement failed: Directory already mounted: /mnt/datalake4b6c87c48101c278/gold\n",
      "\tat com.databricks.backend.daemon.data.client.DbfsClient.send0(DbfsClient.scala:135)\n",
      "\tat com.databricks.backend.daemon.data.client.DbfsClient.sendIdempotent(DbfsClient.scala:69)\n",
      "\tat com.databricks.backend.daemon.dbutils.DBUtilsCore.createOrUpdateMount(DBUtilsCore.scala:1053)\n",
      "\tat com.databricks.backend.daemon.dbutils.DBUtilsCore.$anonfun$mount$1(DBUtilsCore.scala:1079)\n",
      "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperation$1(UsageLogging.scala:560)\n",
      "\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:657)\n",
      "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:678)\n",
      "\tat com.databricks.logging.UsageLogging.$anonfun$withAttributionContext$1(UsageLogging.scala:414)\n",
      "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n",
      "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:158)\n",
      "\tat com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:412)\n",
      "\tat com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:409)\n",
      "\tat com.databricks.backend.daemon.dbutils.FSUtils.withAttributionContext(DBUtilsCore.scala:71)\n",
      "\tat com.databricks.logging.UsageLogging.withAttributionTags(UsageLogging.scala:457)\n",
      "\tat com.databricks.logging.UsageLogging.withAttributionTags$(UsageLogging.scala:442)\n",
      "\tat com.databricks.backend.daemon.dbutils.FSUtils.withAttributionTags(DBUtilsCore.scala:71)\n",
      "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:652)\n",
      "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:569)\n",
      "\tat com.databricks.backend.daemon.dbutils.FSUtils.recordOperationWithResultTags(DBUtilsCore.scala:71)\n",
      "\tat com.databricks.logging.UsageLogging.recordOperation(UsageLogging.scala:560)\n",
      "\tat com.databricks.logging.UsageLogging.recordOperation$(UsageLogging.scala:528)\n",
      "\tat com.databricks.backend.daemon.dbutils.FSUtils.recordOperation(DBUtilsCore.scala:71)\n",
      "\tat com.databricks.backend.daemon.dbutils.FSUtils.recordDbutilsFsOp(DBUtilsCore.scala:135)\n",
      "\tat com.databricks.backend.daemon.dbutils.DBUtilsCore.mount(DBUtilsCore.scala:1073)\n",
      "\tat sun.reflect.GeneratedMethodAccessor1115.invoke(Unknown Source)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:380)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:306)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:195)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:115)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: java.lang.IllegalArgumentException: requirement failed: Directory already mounted: /mnt/datalake4b6c87c48101c278/gold\n",
      "\tat scala.Predef$.require(Predef.scala:281)\n",
      "\tat com.databricks.backend.daemon.data.server.DefaultMetadataManager.$anonfun$insertMount$1(MetadataManager.scala:860)\n",
      "\tat com.databricks.backend.daemon.data.server.DefaultMetadataManager.$anonfun$modifyAndVerify$2(MetadataManager.scala:1242)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat com.databricks.backend.daemon.data.server.DefaultMetadataManager.withRetries(MetadataManager.scala:1015)\n",
      "\tat com.databricks.backend.daemon.data.server.DefaultMetadataManager.modifyAndVerify(MetadataManager.scala:1231)\n",
      "\tat com.databricks.backend.daemon.data.server.DefaultMetadataManager.insertMount(MetadataManager.scala:868)\n",
      "\tat com.databricks.backend.daemon.data.server.handler.MountHandler.receive(MountHandler.scala:131)\n",
      "\tat com.databricks.backend.daemon.data.server.handler.CEMountHandler.receive(MountHandler.scala:175)\n",
      "\tat com.databricks.backend.daemon.data.server.handler.DbfsRequestHandler.receive(DbfsRequestHandler.scala:16)\n",
      "\tat com.databricks.backend.daemon.data.server.handler.DbfsRequestHandler.receive$(DbfsRequestHandler.scala:15)\n",
      "\tat com.databricks.backend.daemon.data.server.handler.MountHandler.receive(MountHandler.scala:39)\n",
      "\tat com.databricks.backend.daemon.data.server.session.SessionContext.$anonfun$queryHandlers$1(SessionContext.scala:54)\n",
      "\tat com.databricks.backend.daemon.data.server.session.SessionContext.$anonfun$queryHandlers$1$adapted(SessionContext.scala:53)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat com.databricks.backend.daemon.data.server.session.SessionContext.queryHandlers(SessionContext.scala:53)\n",
      "\tat com.databricks.backend.daemon.data.server.DbfsServerBackend.$anonfun$handleOtherRpc$2(DbfsServerBackend.scala:599)\n",
      "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)\n",
      "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:290)\n",
      "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n",
      "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:286)\n",
      "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)\n",
      "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)\n",
      "\tat com.databricks.rpc.ServerBackend.withAttributionContext(ServerBackend.scala:22)\n",
      "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:96)\n",
      "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:77)\n",
      "\tat com.databricks.rpc.ServerBackend.withAttributionTags(ServerBackend.scala:22)\n",
      "\tat com.databricks.backend.daemon.data.server.DbfsServerBackend.com$databricks$backend$daemon$data$server$DbfsServerBackend$$handleOtherRpc(DbfsServerBackend.scala:599)\n",
      "\tat com.databricks.backend.daemon.data.server.DbfsServerBackend$$anonfun$receive$1.applyOrElse(DbfsServerBackend.scala:524)\n",
      "\tat com.databricks.backend.daemon.data.server.DbfsServerBackend$$anonfun$receive$1.applyOrElse(DbfsServerBackend.scala:431)\n",
      "\tat com.databricks.rpc.ServerBackend.$anonfun$internalReceive0$2(ServerBackend.scala:174)\n",
      "\tat com.databricks.rpc.ServerBackend$$anonfun$commonReceive$1.applyOrElse(ServerBackend.scala:200)\n",
      "\tat com.databricks.rpc.ServerBackend$$anonfun$commonReceive$1.applyOrElse(ServerBackend.scala:200)\n",
      "\tat com.databricks.rpc.ServerBackend.internalReceive0(ServerBackend.scala:171)\n",
      "\tat com.databricks.rpc.ServerBackend.$anonfun$internalReceive$1(ServerBackend.scala:147)\n",
      "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperation$1(UsageLogging.scala:510)\n",
      "\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:616)\n",
      "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:643)\n",
      "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)\n",
      "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:290)\n",
      "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n",
      "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:286)\n",
      "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)\n",
      "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)\n",
      "\tat com.databricks.rpc.ServerBackend.withAttributionContext(ServerBackend.scala:22)\n",
      "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:96)\n",
      "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:77)\n",
      "\tat com.databricks.rpc.ServerBackend.withAttributionTags(ServerBackend.scala:22)\n",
      "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:611)\n",
      "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:519)\n",
      "\tat com.databricks.rpc.ServerBackend.recordOperationWithResultTags(ServerBackend.scala:22)\n",
      "\tat com.databricks.logging.UsageLogging.recordOperation(UsageLogging.scala:511)\n",
      "\tat com.databricks.logging.UsageLogging.recordOperation$(UsageLogging.scala:475)\n",
      "\tat com.databricks.rpc.ServerBackend.recordOperation(ServerBackend.scala:22)\n",
      "\tat com.databricks.rpc.ServerBackend.internalReceive(ServerBackend.scala:146)\n",
      "\tat com.databricks.rpc.JettyServer$RequestManager.handleRPC(JettyServer.scala:1033)\n",
      "\tat com.databricks.rpc.JettyServer$RequestManager.handleRequestAndRespond(JettyServer.scala:953)\n",
      "\tat com.databricks.rpc.JettyServer$RequestManager.$anonfun$handleHttp$5(JettyServer.scala:548)\n",
      "\tat com.databricks.rpc.JettyServer$RequestManager.$anonfun$handleHttp$5$adapted(JettyServer.scala:513)\n",
      "\tat com.databricks.logging.activity.ActivityContextFactory$.$anonfun$withActivityInternal$12(ActivityContextFactory.scala:860)\n",
      "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)\n",
      "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:290)\n",
      "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n",
      "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:286)\n",
      "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)\n",
      "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)\n",
      "\tat com.databricks.logging.activity.ActivityContextFactory$.withAttributionContext(ActivityContextFactory.scala:53)\n",
      "\tat com.databricks.logging.activity.ActivityContextFactory$.$anonfun$withActivityInternal$2(ActivityContextFactory.scala:860)\n",
      "\tat com.databricks.context.integrity.IntegrityCheckContext$ThreadLocalStorage$.withValue(IntegrityCheckContext.scala:73)\n",
      "\tat com.databricks.logging.activity.ActivityContextFactory$.withActivityInternal(ActivityContextFactory.scala:823)\n",
      "\tat com.databricks.logging.activity.ActivityContextFactory$.withActivityInternal(ActivityContextFactory.scala:805)\n",
      "\tat com.databricks.logging.activity.ActivityContextFactory$.$anonfun$withServiceRequestActivity$15(ActivityContextFactory.scala:291)\n",
      "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)\n",
      "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:290)\n",
      "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n",
      "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:286)\n",
      "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)\n",
      "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)\n",
      "\tat com.databricks.logging.activity.ActivityContextFactory$.withAttributionContext(ActivityContextFactory.scala:53)\n",
      "\tat com.databricks.logging.activity.ActivityContextFactory$.withServiceRequestActivity(ActivityContextFactory.scala:291)\n",
      "\tat com.databricks.rpc.JettyServer$RequestManager.handleHttp(JettyServer.scala:513)\n",
      "\tat com.databricks.rpc.JettyServer$RequestManager.doPost(JettyServer.scala:408)\n",
      "\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:665)\n",
      "\tat com.databricks.rpc.HttpServletWithPatch.service(HttpServletWithPatch.scala:33)\n",
      "\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:750)\n",
      "\tat org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)\n",
      "\tat org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:554)\n",
      "\tat org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:190)\n",
      "\tat org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:505)\n",
      "\tat org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)\n",
      "\tat org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)\n",
      "\tat org.eclipse.jetty.server.Server.handle(Server.java:516)\n",
      "\tat org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:487)\n",
      "\tat org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:732)\n",
      "\tat org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:479)\n",
      "\tat org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)\n",
      "\tat org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)\n",
      "\tat org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)\n",
      "\tat org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)\n",
      "\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338)\n",
      "\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315)\n",
      "\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)\n",
      "\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)\n",
      "\tat org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:409)\n",
      "\tat com.databricks.rpc.InstrumentedQueuedThreadPool$$anon$1.$anonfun$run$2(InstrumentedQueuedThreadPool.scala:110)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)\n",
      "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:290)\n",
      "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n",
      "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:286)\n",
      "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)\n",
      "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)\n",
      "\tat com.databricks.rpc.InstrumentedQueuedThreadPool.withAttributionContext(InstrumentedQueuedThreadPool.scala:45)\n",
      "\tat com.databricks.rpc.InstrumentedQueuedThreadPool$$anon$1.$anonfun$run$1(InstrumentedQueuedThreadPool.scala:110)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat com.databricks.instrumentation.QueuedThreadPoolInstrumenter.trackActiveThreads(QueuedThreadPoolInstrumenter.scala:132)\n",
      "\tat com.databricks.instrumentation.QueuedThreadPoolInstrumenter.trackActiveThreads$(QueuedThreadPoolInstrumenter.scala:129)\n",
      "\tat com.databricks.rpc.InstrumentedQueuedThreadPool.trackActiveThreads(InstrumentedQueuedThreadPool.scala:45)\n",
      "\tat com.databricks.rpc.InstrumentedQueuedThreadPool$$anon$1.run(InstrumentedQueuedThreadPool.scala:92)\n",
      "\tat org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)\n",
      "\tat org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)\n",
      "\tat java.lang.Thread.run(Thread.java:840)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mount_adls('lading-zone')\n",
    "mount_adls('bronze')\n",
    "mount_adls('silver')\n",
    "mount_adls('gold')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fced822b-8bab-437b-8a58-add8a4acd24a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "###Mostrando os pontos de montagem no cluster Databricks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d53984ff-8536-4a33-9e43-acfe34489ab1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>mountPoint</th><th>source</th><th>encryptionType</th></tr></thead><tbody><tr><td>/mnt/datalake6d3129a9a4390b0a/gold</td><td>wasbs://gold@datalake6d3129a9a4390b0a.blob.core.windows.net</td><td></td></tr><tr><td>/mnt/datalakeedda2e0be8d3ec5f/bronze</td><td>wasbs://bronze@datalakeedda2e0be8d3ec5f.blob.core.windows.net</td><td></td></tr><tr><td>/mnt/datalake246d728b13561613/lading-zone</td><td>wasbs://lading-zone@datalake246d728b13561613.blob.core.windows.net</td><td></td></tr><tr><td>/mnt/datalake4b6c87c48101c278/bronze</td><td>wasbs://bronze@datalake4b6c87c48101c278.blob.core.windows.net</td><td></td></tr><tr><td>/mnt/datalake4b6c87c48101c278/gold</td><td>wasbs://gold@datalake4b6c87c48101c278.blob.core.windows.net</td><td></td></tr><tr><td>/databricks-datasets</td><td>databricks-datasets</td><td></td></tr><tr><td>/mnt/datalake246d728b13561613/bronze</td><td>wasbs://bronze@datalake246d728b13561613.blob.core.windows.net</td><td></td></tr><tr><td>/mnt/datalakee66472c14f9678fd/landing-zone</td><td>wasbs://landing-zone@datalakee66472c14f9678fd.blob.core.windows.net</td><td></td></tr><tr><td>/databricks/mlflow-tracking</td><td>databricks/mlflow-tracking</td><td>sse-s3</td></tr><tr><td>/mnt/datalake4b6c87c48101c278/silver</td><td>wasbs://silver@datalake4b6c87c48101c278.blob.core.windows.net</td><td></td></tr><tr><td>/mnt/datalake4b6c87c48101c278/lading-zone</td><td>wasbs://lading-zone@datalake4b6c87c48101c278.blob.core.windows.net</td><td></td></tr><tr><td>/mnt/datalakeedda2e0be8d3ec5f/landing-zone</td><td>wasbs://landing-zone@datalakeedda2e0be8d3ec5f.blob.core.windows.net</td><td></td></tr><tr><td>/databricks-results</td><td>databricks-results</td><td>sse-s3</td></tr><tr><td>/mnt/datalake246d728b13561613/silver</td><td>wasbs://silver@datalake246d728b13561613.blob.core.windows.net</td><td></td></tr><tr><td>/mnt/datalakee66472c14f9678fd/gold</td><td>wasbs://gold@datalakee66472c14f9678fd.blob.core.windows.net</td><td></td></tr><tr><td>/mnt/datalakee66472c14f9678fd/silver</td><td>wasbs://silver@datalakee66472c14f9678fd.blob.core.windows.net</td><td></td></tr><tr><td>/databricks/mlflow-registry</td><td>databricks/mlflow-registry</td><td>sse-s3</td></tr><tr><td>/mnt/datalake6d3129a9a4390b0a/silver</td><td>wasbs://silver@datalake6d3129a9a4390b0a.blob.core.windows.net</td><td></td></tr><tr><td>/mnt/datalake246d728b13561613/gold</td><td>wasbs://gold@datalake246d728b13561613.blob.core.windows.net</td><td></td></tr><tr><td>/mnt/datalake246d728b13561613/landing-zone</td><td>wasbs://landing-zone@datalake246d728b13561613.blob.core.windows.net</td><td></td></tr><tr><td>/mnt/datalakeedda2e0be8d3ec5f/gold</td><td>wasbs://gold@datalakeedda2e0be8d3ec5f.blob.core.windows.net</td><td></td></tr><tr><td>/mnt/datalakeedda2e0be8d3ec5f/lading-zone</td><td>wasbs://lading-zone@datalakeedda2e0be8d3ec5f.blob.core.windows.net</td><td></td></tr><tr><td>/mnt/datalakee66472c14f9678fd/lading-zone</td><td>wasbs://lading-zone@datalakee66472c14f9678fd.blob.core.windows.net</td><td></td></tr><tr><td>/mnt/datalake6d3129a9a4390b0a/bronze</td><td>wasbs://bronze@datalake6d3129a9a4390b0a.blob.core.windows.net</td><td></td></tr><tr><td>/mnt/datalakeedda2e0be8d3ec5f/silver</td><td>wasbs://silver@datalakeedda2e0be8d3ec5f.blob.core.windows.net</td><td></td></tr><tr><td>/mnt/datalake6d3129a9a4390b0a/landing-zone</td><td>wasbs://landing-zone@datalake6d3129a9a4390b0a.blob.core.windows.net</td><td></td></tr><tr><td>/mnt/datalake4b6c87c48101c278/landing-zone</td><td>wasbs://landing-zone@datalake4b6c87c48101c278.blob.core.windows.net</td><td></td></tr><tr><td>/</td><td>DatabricksRoot</td><td>sse-s3</td></tr><tr><td>/mnt/datalake6d3129a9a4390b0a/lading-zone</td><td>wasbs://lading-zone@datalake6d3129a9a4390b0a.blob.core.windows.net</td><td></td></tr><tr><td>/mnt/datalakee66472c14f9678fd/bronze</td><td>wasbs://bronze@datalakee66472c14f9678fd.blob.core.windows.net</td><td></td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "/mnt/datalake6d3129a9a4390b0a/gold",
         "wasbs://gold@datalake6d3129a9a4390b0a.blob.core.windows.net",
         ""
        ],
        [
         "/mnt/datalakeedda2e0be8d3ec5f/bronze",
         "wasbs://bronze@datalakeedda2e0be8d3ec5f.blob.core.windows.net",
         ""
        ],
        [
         "/mnt/datalake246d728b13561613/lading-zone",
         "wasbs://lading-zone@datalake246d728b13561613.blob.core.windows.net",
         ""
        ],
        [
         "/mnt/datalake4b6c87c48101c278/bronze",
         "wasbs://bronze@datalake4b6c87c48101c278.blob.core.windows.net",
         ""
        ],
        [
         "/mnt/datalake4b6c87c48101c278/gold",
         "wasbs://gold@datalake4b6c87c48101c278.blob.core.windows.net",
         ""
        ],
        [
         "/databricks-datasets",
         "databricks-datasets",
         ""
        ],
        [
         "/mnt/datalake246d728b13561613/bronze",
         "wasbs://bronze@datalake246d728b13561613.blob.core.windows.net",
         ""
        ],
        [
         "/mnt/datalakee66472c14f9678fd/landing-zone",
         "wasbs://landing-zone@datalakee66472c14f9678fd.blob.core.windows.net",
         ""
        ],
        [
         "/databricks/mlflow-tracking",
         "databricks/mlflow-tracking",
         "sse-s3"
        ],
        [
         "/mnt/datalake4b6c87c48101c278/silver",
         "wasbs://silver@datalake4b6c87c48101c278.blob.core.windows.net",
         ""
        ],
        [
         "/mnt/datalake4b6c87c48101c278/lading-zone",
         "wasbs://lading-zone@datalake4b6c87c48101c278.blob.core.windows.net",
         ""
        ],
        [
         "/mnt/datalakeedda2e0be8d3ec5f/landing-zone",
         "wasbs://landing-zone@datalakeedda2e0be8d3ec5f.blob.core.windows.net",
         ""
        ],
        [
         "/databricks-results",
         "databricks-results",
         "sse-s3"
        ],
        [
         "/mnt/datalake246d728b13561613/silver",
         "wasbs://silver@datalake246d728b13561613.blob.core.windows.net",
         ""
        ],
        [
         "/mnt/datalakee66472c14f9678fd/gold",
         "wasbs://gold@datalakee66472c14f9678fd.blob.core.windows.net",
         ""
        ],
        [
         "/mnt/datalakee66472c14f9678fd/silver",
         "wasbs://silver@datalakee66472c14f9678fd.blob.core.windows.net",
         ""
        ],
        [
         "/databricks/mlflow-registry",
         "databricks/mlflow-registry",
         "sse-s3"
        ],
        [
         "/mnt/datalake6d3129a9a4390b0a/silver",
         "wasbs://silver@datalake6d3129a9a4390b0a.blob.core.windows.net",
         ""
        ],
        [
         "/mnt/datalake246d728b13561613/gold",
         "wasbs://gold@datalake246d728b13561613.blob.core.windows.net",
         ""
        ],
        [
         "/mnt/datalake246d728b13561613/landing-zone",
         "wasbs://landing-zone@datalake246d728b13561613.blob.core.windows.net",
         ""
        ],
        [
         "/mnt/datalakeedda2e0be8d3ec5f/gold",
         "wasbs://gold@datalakeedda2e0be8d3ec5f.blob.core.windows.net",
         ""
        ],
        [
         "/mnt/datalakeedda2e0be8d3ec5f/lading-zone",
         "wasbs://lading-zone@datalakeedda2e0be8d3ec5f.blob.core.windows.net",
         ""
        ],
        [
         "/mnt/datalakee66472c14f9678fd/lading-zone",
         "wasbs://lading-zone@datalakee66472c14f9678fd.blob.core.windows.net",
         ""
        ],
        [
         "/mnt/datalake6d3129a9a4390b0a/bronze",
         "wasbs://bronze@datalake6d3129a9a4390b0a.blob.core.windows.net",
         ""
        ],
        [
         "/mnt/datalakeedda2e0be8d3ec5f/silver",
         "wasbs://silver@datalakeedda2e0be8d3ec5f.blob.core.windows.net",
         ""
        ],
        [
         "/mnt/datalake6d3129a9a4390b0a/landing-zone",
         "wasbs://landing-zone@datalake6d3129a9a4390b0a.blob.core.windows.net",
         ""
        ],
        [
         "/mnt/datalake4b6c87c48101c278/landing-zone",
         "wasbs://landing-zone@datalake4b6c87c48101c278.blob.core.windows.net",
         ""
        ],
        [
         "/",
         "DatabricksRoot",
         "sse-s3"
        ],
        [
         "/mnt/datalake6d3129a9a4390b0a/lading-zone",
         "wasbs://lading-zone@datalake6d3129a9a4390b0a.blob.core.windows.net",
         ""
        ],
        [
         "/mnt/datalakee66472c14f9678fd/bronze",
         "wasbs://bronze@datalakee66472c14f9678fd.blob.core.windows.net",
         ""
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "mountPoint",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "source",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "encryptionType",
         "type": "\"string\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(dbutils.fs.mounts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1f6ec630-db65-41cb-9fdf-a941cfafe400",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Mostrando todos os arquivos da camada bronze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "295f6535-5ab1-43af-a1d3-fadec36b766b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>path</th><th>name</th><th>size</th><th>modificationTime</th></tr></thead><tbody><tr><td>dbfs:/mnt/datalake4b6c87c48101c278/bronze/customers/</td><td>customers/</td><td>0</td><td>0</td></tr><tr><td>dbfs:/mnt/datalake4b6c87c48101c278/bronze/geolocation/</td><td>geolocation/</td><td>0</td><td>0</td></tr><tr><td>dbfs:/mnt/datalake4b6c87c48101c278/bronze/leads_closed/</td><td>leads_closed/</td><td>0</td><td>0</td></tr><tr><td>dbfs:/mnt/datalake4b6c87c48101c278/bronze/leads_qualified/</td><td>leads_qualified/</td><td>0</td><td>0</td></tr><tr><td>dbfs:/mnt/datalake4b6c87c48101c278/bronze/order_items/</td><td>order_items/</td><td>0</td><td>0</td></tr><tr><td>dbfs:/mnt/datalake4b6c87c48101c278/bronze/order_payments/</td><td>order_payments/</td><td>0</td><td>0</td></tr><tr><td>dbfs:/mnt/datalake4b6c87c48101c278/bronze/order_reviews/</td><td>order_reviews/</td><td>0</td><td>0</td></tr><tr><td>dbfs:/mnt/datalake4b6c87c48101c278/bronze/orders/</td><td>orders/</td><td>0</td><td>0</td></tr><tr><td>dbfs:/mnt/datalake4b6c87c48101c278/bronze/product_category_name_translation/</td><td>product_category_name_translation/</td><td>0</td><td>0</td></tr><tr><td>dbfs:/mnt/datalake4b6c87c48101c278/bronze/products/</td><td>products/</td><td>0</td><td>0</td></tr><tr><td>dbfs:/mnt/datalake4b6c87c48101c278/bronze/sellers/</td><td>sellers/</td><td>0</td><td>0</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "dbfs:/mnt/datalake4b6c87c48101c278/bronze/customers/",
         "customers/",
         0,
         0
        ],
        [
         "dbfs:/mnt/datalake4b6c87c48101c278/bronze/geolocation/",
         "geolocation/",
         0,
         0
        ],
        [
         "dbfs:/mnt/datalake4b6c87c48101c278/bronze/leads_closed/",
         "leads_closed/",
         0,
         0
        ],
        [
         "dbfs:/mnt/datalake4b6c87c48101c278/bronze/leads_qualified/",
         "leads_qualified/",
         0,
         0
        ],
        [
         "dbfs:/mnt/datalake4b6c87c48101c278/bronze/order_items/",
         "order_items/",
         0,
         0
        ],
        [
         "dbfs:/mnt/datalake4b6c87c48101c278/bronze/order_payments/",
         "order_payments/",
         0,
         0
        ],
        [
         "dbfs:/mnt/datalake4b6c87c48101c278/bronze/order_reviews/",
         "order_reviews/",
         0,
         0
        ],
        [
         "dbfs:/mnt/datalake4b6c87c48101c278/bronze/orders/",
         "orders/",
         0,
         0
        ],
        [
         "dbfs:/mnt/datalake4b6c87c48101c278/bronze/product_category_name_translation/",
         "product_category_name_translation/",
         0,
         0
        ],
        [
         "dbfs:/mnt/datalake4b6c87c48101c278/bronze/products/",
         "products/",
         0,
         0
        ],
        [
         "dbfs:/mnt/datalake4b6c87c48101c278/bronze/sellers/",
         "sellers/",
         0,
         0
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "path",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "size",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "modificationTime",
         "type": "\"long\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(dbutils.fs.ls(f\"/mnt/{storageAccountName}/bronze\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1ef3c883-3b0f-44cb-8917-49f1f1fd3819",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "###Gerando um dataframe dos delta lake no container bronze do Azure Data Lake Storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "37774595-e2cd-4ba0-92aa-4a6f239c0e7b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_customers   = spark.read.format('delta').load(f\"/mnt/{storageAccountName}/bronze/customers\")\n",
    "df_geolocation     = spark.read.format('delta').load(f\"/mnt/{storageAccountName}/bronze/geolocation\")\n",
    "df_leads_closed   = spark.read.format('delta').load(f\"/mnt/{storageAccountName}/bronze/leads_closed\")\n",
    "df_leads_qualified  = spark.read.format('delta').load(f\"/mnt/{storageAccountName}/bronze/leads_qualified\")\n",
    "df_order_items    = spark.read.format('delta').load(f\"/mnt/{storageAccountName}/bronze/order_items\")\n",
    "df_order_payments     = spark.read.format('delta').load(f\"/mnt/{storageAccountName}/bronze/order_payments\")\n",
    "df_order_reviews    = spark.read.format('delta').load(f\"/mnt/{storageAccountName}/bronze/order_reviews\")\n",
    "df_orders = spark.read.format('delta').load(f\"/mnt/{storageAccountName}/bronze/orders\")\n",
    "df_product_category_name_translation    = spark.read.format('delta').load(f\"/mnt/{storageAccountName}/bronze/product_category_name_translation\")\n",
    "df_products  = spark.read.format('delta').load(f\"/mnt/{storageAccountName}/bronze/products\")\n",
    "df_sellers  = spark.read.format('delta').load(f\"/mnt/{storageAccountName}/bronze/sellers\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e4ffc23f-8add-4747-b572-b470a7e5eb8f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Adicionando metadados de data e hora de processamento e nome do arquivo de origem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f278962e-c91a-4900-ba19-27d9b9e08947",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import current_timestamp, lit\n",
    "\n",
    "df_customers   = df_customers.withColumn(\"data_hora_silver\", current_timestamp()).withColumn(\"nome_arquivo\", lit(\"customers\"))\n",
    "df_geolocation     = df_geolocation.withColumn(\"data_hora_silver\", current_timestamp()).withColumn(\"nome_arquivo\", lit(\"geolocation\"))\n",
    "df_leads_closed   = df_leads_closed.withColumn(\"data_hora_silver\", current_timestamp()).withColumn(\"nome_arquivo\", lit(\"leads_closed\"))\n",
    "df_leads_qualified  = df_leads_qualified.withColumn(\"data_hora_silver\", current_timestamp()).withColumn(\"nome_arquivo\", lit(\"leads_qualified\"))\n",
    "df_order_items    = df_order_items.withColumn(\"data_hora_silver\", current_timestamp()).withColumn(\"nome_arquivo\", lit(\"order_items\"))\n",
    "df_order_payments     = df_order_payments.withColumn(\"data_hora_silver\", current_timestamp()).withColumn(\"nome_arquivo\", lit(\"order_payments\"))\n",
    "df_order_reviews    = df_order_reviews.withColumn(\"data_hora_silver\", current_timestamp()).withColumn(\"nome_arquivo\", lit(\"order_reviews\"))\n",
    "df_orders = df_orders.withColumn(\"data_hora_silver\", current_timestamp()).withColumn(\"nome_arquivo\", lit(\"orders\"))\n",
    "df_product_category_name_translation    = df_product_category_name_translation.withColumn(\"data_hora_silver\", current_timestamp()).withColumn(\"nome_arquivo\", lit(\"product_category_name_translation\"))\n",
    "df_products  = df_products.withColumn(\"data_hora_silver\", current_timestamp()).withColumn(\"nome_arquivo\", lit(\"products\"))\n",
    "df_sellers  = df_sellers.withColumn(\"data_hora_silver\", current_timestamp()).withColumn(\"nome_arquivo\", lit(\"sellers\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a1fd697a-b470-4d9e-a5fe-116e518716cc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Colunas do DataFrame 'df_customers' em maiúsculas:\n",
      "CUSTOMER_ID\n",
      "CUSTOMER_UNIQUE_ID\n",
      "CUSTOMER_ZIP_CODE_PREFIX\n",
      "CUSTOMER_CITY\n",
      "CUSTOMER_STATE\n",
      "DATA_HORA_BRONZE\n",
      "NOME_ARQUIVO\n",
      "DATA_HORA_SILVER\n",
      "\n",
      "Colunas do DataFrame 'df_geolocation' em maiúsculas:\n",
      "GEOLOCATION_ZIP_CODE_PREFIX\n",
      "GEOLOCATION_LAT\n",
      "GEOLOCATION_LNG\n",
      "GEOLOCATION_CITY\n",
      "GEOLOCATION_STATE\n",
      "DATA_HORA_BRONZE\n",
      "NOME_ARQUIVO\n",
      "DATA_HORA_SILVER\n",
      "\n",
      "Colunas do DataFrame 'df_leads_closed' em maiúsculas:\n",
      "MQL_ID\n",
      "SELLER_ID\n",
      "SDR_ID\n",
      "SR_ID\n",
      "WON_DATE\n",
      "BUSINESS_SEGMENT\n",
      "LEAD_TYPE\n",
      "LEAD_BEHAVIOUR_PROFILE\n",
      "HAS_COMPANY\n",
      "HAS_GTIN\n",
      "AVERAGE_STOCK\n",
      "BUSINESS_TYPE\n",
      "DECLARED_PRODUCT_CATALOG_SIZE\n",
      "DECLARED_MONTHLY_REVENUE\n",
      "DATA_HORA_BRONZE\n",
      "NOME_ARQUIVO\n",
      "DATA_HORA_SILVER\n",
      "\n",
      "Colunas do DataFrame 'df_leads_qualified' em maiúsculas:\n",
      "MQL_ID\n",
      "FIRST_CONTACT_DATE\n",
      "LANDING_PAGE_ID\n",
      "ORIGIN\n",
      "DATA_HORA_BRONZE\n",
      "NOME_ARQUIVO\n",
      "DATA_HORA_SILVER\n",
      "\n",
      "Colunas do DataFrame 'df_order_items' em maiúsculas:\n",
      "ORDER_ID\n",
      "ORDER_ITEM_ID\n",
      "PRODUCT_ID\n",
      "SELLER_ID\n",
      "SHIPPING_LIMIT_DATE\n",
      "PRICE\n",
      "FREIGHT_VALUE\n",
      "DATA_HORA_BRONZE\n",
      "NOME_ARQUIVO\n",
      "DATA_HORA_SILVER\n",
      "\n",
      "Colunas do DataFrame 'df_order_payments' em maiúsculas:\n",
      "ORDER_ID\n",
      "PAYMENT_SEQUENTIAL\n",
      "PAYMENT_TYPE\n",
      "PAYMENT_INSTALLMENTS\n",
      "PAYMENT_VALUE\n",
      "DATA_HORA_BRONZE\n",
      "NOME_ARQUIVO\n",
      "DATA_HORA_SILVER\n",
      "\n",
      "Colunas do DataFrame 'df_order_reviews' em maiúsculas:\n",
      "REVIEW_ID\n",
      "ORDER_ID\n",
      "REVIEW_SCORE\n",
      "REVIEW_COMMENT_TITLE\n",
      "REVIEW_COMMENT_MESSAGE\n",
      "REVIEW_CREATION_DATE\n",
      "REVIEW_ANSWER_TIMESTAMP\n",
      "DATA_HORA_BRONZE\n",
      "NOME_ARQUIVO\n",
      "DATA_HORA_SILVER\n",
      "\n",
      "Colunas do DataFrame 'df_orders' em maiúsculas:\n",
      "ORDER_ID\n",
      "CUSTOMER_ID\n",
      "ORDER_STATUS\n",
      "ORDER_PURCHASE_TIMESTAMP\n",
      "ORDER_APPROVED_AT\n",
      "ORDER_DELIVERED_CARRIER_DATE\n",
      "ORDER_DELIVERED_CUSTOMER_DATE\n",
      "ORDER_ESTIMATED_DELIVERY_DATE\n",
      "DATA_HORA_BRONZE\n",
      "NOME_ARQUIVO\n",
      "DATA_HORA_SILVER\n",
      "\n",
      "Colunas do DataFrame 'df_product_category_name_translation' em maiúsculas:\n",
      "PRODUCT_CATEGORY_NAME\n",
      "PRODUCT_CATEGORY_NAME_ENGLISH\n",
      "DATA_HORA_BRONZE\n",
      "NOME_ARQUIVO\n",
      "DATA_HORA_SILVER\n",
      "\n",
      "Colunas do DataFrame 'df_products' em maiúsculas:\n",
      "PRODUCT_ID\n",
      "PRODUCT_CATEGORY_NAME\n",
      "PRODUCT_NAME_LENGHT\n",
      "PRODUCT_DESCRIPTION_LENGHT\n",
      "PRODUCT_PHOTOS_QTY\n",
      "PRODUCT_WEIGHT_G\n",
      "PRODUCT_LENGTH_CM\n",
      "PRODUCT_HEIGHT_CM\n",
      "PRODUCT_WIDTH_CM\n",
      "DATA_HORA_BRONZE\n",
      "NOME_ARQUIVO\n",
      "DATA_HORA_SILVER\n",
      "\n",
      "Colunas do DataFrame 'df_sellers' em maiúsculas:\n",
      "SELLER_ID\n",
      "SELLER_ZIP_CODE_PREFIX\n",
      "SELLER_CITY\n",
      "SELLER_STATE\n",
      "DATA_HORA_BRONZE\n",
      "NOME_ARQUIVO\n",
      "DATA_HORA_SILVER\n"
     ]
    }
   ],
   "source": [
    "def imprimir_colunas_maiusculas(dataframes):\n",
    "    for nome_df, df in dataframes:\n",
    "        print(f\"\\nColunas do DataFrame '{nome_df}' em maiúsculas:\")\n",
    "        colunas_maiusculas = [coluna.upper() for coluna in df.columns]\n",
    "        for coluna in colunas_maiusculas:\n",
    "            print(coluna)\n",
    "\n",
    "# Lista com tuplas (nome do DataFrame, DataFrame em si)\n",
    "dataframes = [\n",
    "    (\"df_customers\", df_customers),\n",
    "    (\"df_geolocation\", df_geolocation),\n",
    "    (\"df_leads_closed\", df_leads_closed),\n",
    "    (\"df_leads_qualified\", df_leads_qualified),\n",
    "    (\"df_order_items\", df_order_items),\n",
    "    (\"df_order_payments\", df_order_payments),\n",
    "    (\"df_order_reviews\", df_order_reviews),\n",
    "    (\"df_orders\", df_orders),\n",
    "    (\"df_product_category_name_translation\", df_product_category_name_translation),\n",
    "    (\"df_products\", df_products),\n",
    "    (\"df_sellers\", df_sellers)\n",
    "]\n",
    "\n",
    "# Chamada da função\n",
    "imprimir_colunas_maiusculas(dataframes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9335815b-0449-472d-af38-4729d26a54c6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "###Mudando as colunas para maiscula e ajustanto os nomes das colunas de acordo com o dicionario de dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "90da7da5-75e6-4f0d-bb38-6ff90b321417",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "df_apolice = (\n",
    "\tdf_apolice\n",
    "\t.withColumnRenamed(\"cd_apolice\"         , \"CODIGO_APOLICE\")\n",
    "\t.withColumnRenamed(\"cd_cliente\"         , \"CODIGO_CLIENTE\")\n",
    "\t.withColumnRenamed(\"dt_inicio_vigencia\" , \"DATA_INICIO_VIGENCIA\")\n",
    "\t.withColumnRenamed(\"dt_fim_vigencia\"    , \"DATA_FIM_VIGENCIA\")\n",
    "\t.withColumnRenamed(\"vl_cobertura\"       , \"VALOR_COBERTURA\")\n",
    "\t.withColumnRenamed(\"vl_franquia\"        , \"VALOR_FRANQUIA\")\n",
    "\t.withColumnRenamed(\"placa\"              , \"PLACA\")\n",
    "\t.drop(\"data_hora_bronze\")\n",
    "\t.withColumnRenamed(\"nome_arquivo\"       , \"NOME_ARQUIVO_BRONZE\")\n",
    "\t.withColumnRenamed(\"data_hora_silver\"   , \"DATA_HORA_SILVER\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2c1dc9e5-dfb1-4ef9-b407-a711baf6c81f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "###Visualiza o dataframe atualizado para silver"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "13177ea0-6204-4a2a-9352-d6057d8cd434",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "df_apolice.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8d908b82-ff93-4bb6-af69-ec5655308a8f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "###Salvando os dataframes em delta lake (formato de arquivo) no data lake (repositorio cloud)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bb02cf44-9572-4ee1-8830-c3671012ec49",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "df_apolice.write.format('delta').save(f\"/mnt/{storageAccountName}/silver/apolice\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "511bb1d8-ea04-4a9c-93c4-6b8228f00830",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "###Verificando os dados gravados em delta na camada silver"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6e8454d0-a9de-40dc-b55d-a8aa0156f93f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "display(dbutils.fs.ls(f\"/mnt/{storageAccountName}/silver/\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f6393fa5-64f2-4e8d-8358-617d0b55f035",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Lendo um exemplo de um delta lake para validar a existencia dos dados e das colunas do metadados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "84ef9829-3e0e-4807-bc1b-026324f6ed82",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "spark.read.format('delta').load(f'/mnt/{storageAccountName}/silver/apolice').limit(10).display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "535211c1-52b7-40c9-a8e2-7a33962fb181",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### BONUS - Efetuando a mesma atividade da silver (listada acima) de forma massiva em todos os arquivos delta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a0142014-ae9e-4f1e-a9a4-b77e08d01358",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Fazer as transformacoes de forma massiva"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "35ef7fda-3ad5-447a-892e-16429040fa37",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Fucao para renomear as colunas de cada delta table para maiuscula e ajusta o nome das colunas de acordo com o dicionario de dados\n",
    "def renomear_colunas(diretorio):\n",
    "\n",
    "    # Carregue o DataFrame a partir do delta\n",
    "    df = spark.read.format('delta').load(diretorio)\n",
    "\n",
    "    tabela = diretorio.split('/')[-2]\n",
    "\n",
    "    # Renomeie todas as colunas para maiúsculas e faça a substituição do padrão \"cd_\" para \"codigo_\"\n",
    "    for coluna in df.columns:\n",
    "        novo_nome = coluna.upper()\n",
    "        novo_nome = novo_nome.replace(\"_ID\", \"_CODIGO\")\n",
    "        novo_nome = novo_nome.replace(\"_QTY\", \"_QUANTIDADE\")\n",
    "        novo_nome = novo_nome.replace(\"_LAT\", \"_LATITUDE\")\n",
    "        novo_nome = novo_nome.replace(\"_LNG\", \"_LONGITUDE\")\n",
    "        novo_nome = novo_nome.replace(\"_CITY\", \"_CIDADE\")\n",
    "        novo_nome = novo_nome.replace(\"_STATE\", \"_ESTADO\")\n",
    "        novo_nome = novo_nome.replace(\"_DATE\", \"_DATA\")\n",
    "        novo_nome = novo_nome.replace(\"_SEGMENT\", \"_SEGMENTO\")\n",
    "        novo_nome = novo_nome.replace(\"_TYPE\", \"_TIPO\")\n",
    "        novo_nome = novo_nome.replace(\"_PROFILE\", \"_PERFIL\")\n",
    "        novo_nome = novo_nome.replace(\"_COMPANY\", \"_EMPRESA\")\n",
    "        novo_nome = novo_nome.replace(\"_SIZE\", \"_TAMANHO\")\n",
    "        novo_nome = novo_nome.replace(\"_VALUE\", \"_VALOR\")\n",
    "        novo_nome = novo_nome.replace(\"_SEQUENTIAL\", \"_SEQUENCIA\")\n",
    "        novo_nome = novo_nome.replace(\"_SCORE\", \"_PONTUACAO\")\n",
    "        novo_nome = novo_nome.replace(\"_TITLE\", \"_TITULO\")\n",
    "        novo_nome = novo_nome.replace(\"_MESSAGE\", \"_MENSAGEM\")\n",
    "        novo_nome = novo_nome.replace(\"_INSTALLMENTS\", \"_PARCELAS\")\n",
    "        novo_nome = novo_nome.replace(\"_NAME\", \"_NOME\")\n",
    "        novo_nome = novo_nome.replace(\"_LENGHT\", \"_COMPRIMENTO\")\n",
    "        novo_nome = novo_nome.replace(\"_G\", \"_GRAMAS\")\n",
    "        novo_nome = novo_nome.replace(\"_CM\", \"_CENTIMETROS\")\n",
    "        novo_nome = novo_nome.replace(\"_PREFIX\", \"_PREFIXO\")\n",
    "\n",
    "        df = df.withColumnRenamed(coluna, novo_nome)\n",
    "        df = df.drop(\"DATA_HORA_BRONZE\")\n",
    "        df = df.drop(\"NOME_ARQUIVO\")\n",
    "        df = df.withColumn(\"NOME_ARQUIVO_BRONZE\", lit(tabela))\n",
    "        df = df.withColumn(\"DATA_ARQUIVO_SILVER\", current_timestamp())\n",
    "\n",
    "    # Salve o DataFrame modificado de volta no mesmo local\n",
    "    #df.display()\n",
    "    df.write.format('delta').save(f\"/mnt/{storageAccountName}/silver/{tabela}\")\n",
    "\n",
    "#Funcao que chama a funcao renomear colunas para todos os arquivos contidos no container\n",
    "def renomear_arquivos_delta(diretorio):\n",
    "\n",
    "    # Lista para armazenar os nomes dos arquivos delta\n",
    "    nomes_arquivos_delta = []\n",
    "\n",
    "    # Lista os arquivos no diretório\n",
    "    arquivos = dbutils.fs.ls(diretorio)\n",
    "    \n",
    "    # Itera sobre os arquivos e armazena os nomes dos arquivos delta\n",
    "    for arquivo in arquivos:\n",
    "        nome_arquivo = arquivo.path\n",
    "        # Remover as aspas e a barra (/) no final do nome do arquivo\n",
    "        #nome_arquivo = nome_arquivo.rstrip('/')\n",
    "        #nomes_arquivos_delta.append(nome_arquivo)\n",
    "        renomear_colunas(nome_arquivo)\n",
    "        #print(nome_arquivo)\n",
    "\n",
    "    return nomes_arquivos_delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9f1daab8-07de-459e-ac48-855cb49780a2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[38]: []"
     ]
    }
   ],
   "source": [
    "# Executa a funcao para atualizar todos os dataframes\n",
    "diretorio = f'/mnt/{storageAccountName}/bronze'\n",
    "\n",
    "renomear_arquivos_delta(diretorio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5c725b8e-a396-4a66-b98a-c380f9be8901",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>CUSTOMER_CODIGO</th><th>CUSTOMER_UNIQUE_CODIGO</th><th>CUSTOMER_ZIP_CODE_PREFIXO</th><th>CUSTOMER_CIDADE</th><th>CUSTOMER_ESTADO</th><th>NOME_ARQUIVO_BRONZE</th><th>DATA_ARQUIVO_SILVER</th></tr></thead><tbody><tr><td>06b8999e2fba1a1fbc88172c00ba8bc7</td><td>861eff4711a542e4b93843c6dd7febb0</td><td>14409</td><td>franca</td><td>SP</td><td>customers</td><td>2025-06-07T04:30:16.007+0000</td></tr><tr><td>18955e83d337fd6b2def6b18a428ac77</td><td>290c77bc529b7ac935b93aa66c333dc3</td><td>9790</td><td>sao bernardo do campo</td><td>SP</td><td>customers</td><td>2025-06-07T04:30:16.007+0000</td></tr><tr><td>4e7b3e00288586ebd08712fdd0374a03</td><td>060e732b5b29e8181a18229c7b0b2b5e</td><td>1151</td><td>sao paulo</td><td>SP</td><td>customers</td><td>2025-06-07T04:30:16.007+0000</td></tr><tr><td>b2b6027bc5c5109e529d4dc6358b12c3</td><td>259dac757896d24d7702b9acbbff3f3c</td><td>8775</td><td>mogi das cruzes</td><td>SP</td><td>customers</td><td>2025-06-07T04:30:16.007+0000</td></tr><tr><td>4f2d8ab171c80ec8364f7c12e35b23ad</td><td>345ecd01c38d18a9036ed96c73b8d066</td><td>13056</td><td>campinas</td><td>SP</td><td>customers</td><td>2025-06-07T04:30:16.007+0000</td></tr><tr><td>879864dab9bc3047522c92c82e1212b8</td><td>4c93744516667ad3b8f1fb645a3116a4</td><td>89254</td><td>jaragua do sul</td><td>SC</td><td>customers</td><td>2025-06-07T04:30:16.007+0000</td></tr><tr><td>fd826e7cf63160e536e0908c76c3f441</td><td>addec96d2e059c80c30fe6871d30d177</td><td>4534</td><td>sao paulo</td><td>SP</td><td>customers</td><td>2025-06-07T04:30:16.007+0000</td></tr><tr><td>5e274e7a0c3809e14aba7ad5aae0d407</td><td>57b2a98a409812fe9618067b6b8ebe4f</td><td>35182</td><td>timoteo</td><td>MG</td><td>customers</td><td>2025-06-07T04:30:16.007+0000</td></tr><tr><td>5adf08e34b2e993982a47070956c5c65</td><td>1175e95fb47ddff9de6b2b06188f7e0d</td><td>81560</td><td>curitiba</td><td>PR</td><td>customers</td><td>2025-06-07T04:30:16.007+0000</td></tr><tr><td>4b7139f34592b3a31687243a302fa75b</td><td>9afe194fb833f79e300e37e580171f22</td><td>30575</td><td>belo horizonte</td><td>MG</td><td>customers</td><td>2025-06-07T04:30:16.007+0000</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "06b8999e2fba1a1fbc88172c00ba8bc7",
         "861eff4711a542e4b93843c6dd7febb0",
         "14409",
         "franca",
         "SP",
         "customers",
         "2025-06-07T04:30:16.007+0000"
        ],
        [
         "18955e83d337fd6b2def6b18a428ac77",
         "290c77bc529b7ac935b93aa66c333dc3",
         "9790",
         "sao bernardo do campo",
         "SP",
         "customers",
         "2025-06-07T04:30:16.007+0000"
        ],
        [
         "4e7b3e00288586ebd08712fdd0374a03",
         "060e732b5b29e8181a18229c7b0b2b5e",
         "1151",
         "sao paulo",
         "SP",
         "customers",
         "2025-06-07T04:30:16.007+0000"
        ],
        [
         "b2b6027bc5c5109e529d4dc6358b12c3",
         "259dac757896d24d7702b9acbbff3f3c",
         "8775",
         "mogi das cruzes",
         "SP",
         "customers",
         "2025-06-07T04:30:16.007+0000"
        ],
        [
         "4f2d8ab171c80ec8364f7c12e35b23ad",
         "345ecd01c38d18a9036ed96c73b8d066",
         "13056",
         "campinas",
         "SP",
         "customers",
         "2025-06-07T04:30:16.007+0000"
        ],
        [
         "879864dab9bc3047522c92c82e1212b8",
         "4c93744516667ad3b8f1fb645a3116a4",
         "89254",
         "jaragua do sul",
         "SC",
         "customers",
         "2025-06-07T04:30:16.007+0000"
        ],
        [
         "fd826e7cf63160e536e0908c76c3f441",
         "addec96d2e059c80c30fe6871d30d177",
         "4534",
         "sao paulo",
         "SP",
         "customers",
         "2025-06-07T04:30:16.007+0000"
        ],
        [
         "5e274e7a0c3809e14aba7ad5aae0d407",
         "57b2a98a409812fe9618067b6b8ebe4f",
         "35182",
         "timoteo",
         "MG",
         "customers",
         "2025-06-07T04:30:16.007+0000"
        ],
        [
         "5adf08e34b2e993982a47070956c5c65",
         "1175e95fb47ddff9de6b2b06188f7e0d",
         "81560",
         "curitiba",
         "PR",
         "customers",
         "2025-06-07T04:30:16.007+0000"
        ],
        [
         "4b7139f34592b3a31687243a302fa75b",
         "9afe194fb833f79e300e37e580171f22",
         "30575",
         "belo horizonte",
         "MG",
         "customers",
         "2025-06-07T04:30:16.007+0000"
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "CUSTOMER_CODIGO",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "CUSTOMER_UNIQUE_CODIGO",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "CUSTOMER_ZIP_CODE_PREFIXO",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "CUSTOMER_CIDADE",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "CUSTOMER_ESTADO",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "NOME_ARQUIVO_BRONZE",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "DATA_ARQUIVO_SILVER",
         "type": "\"timestamp\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "spark.read.format('delta').load(f'/mnt/{storageAccountName}/silver/customers').limit(10).display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d0a8d2b2-7ec4-4b3d-ad99-d0658248d475",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arquivos no diretório:\n",
      "customers CUSTOMERS\n",
      "geolocation GEOLOCATION\n",
      "leads_closed LEADS_CLOSED\n",
      "leads_qualified LEADS_QUALIFIED\n",
      "order_items ORDER_ITEMS\n",
      "order_payments ORDER_PAYMENTS\n",
      "order_reviews ORDER_REVIEWS\n",
      "orders ORDERS\n",
      "product_category_name_translation PRODUCT_CATEGORY_NAME_TRANSLATION\n",
      "products PRODUCTS\n",
      "sellers SELLERS\n"
     ]
    }
   ],
   "source": [
    "#Funcao auxiliar\n",
    "import os\n",
    "\n",
    "# Use a função para renomear as colunas para maiúsculo em um diretório específico\n",
    "diretorio = f'/mnt/{storageAccountName}/bronze/'\n",
    "\n",
    "arquivos = dbutils.fs.ls(diretorio)\n",
    "\n",
    "# Imprime os nomes dos arquivos\n",
    "print(\"Arquivos no diretório:\")\n",
    "for arquivo in arquivos:\n",
    "    print(arquivo.name.rstrip('/'), arquivo.name.rstrip('/').upper())"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 3210653005600686,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "Atividade Pratica - Lakehouse - Silver",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
